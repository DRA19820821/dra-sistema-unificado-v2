# backend/agents/mapas/nodes/divisor_node.py
"""
Node do LLM01 - Divisor de Conte√∫do.
VERS√ÉO COM IMPORTS CORRIGIDOS
"""

from ..state import MindmapState
from backend.services.llm_factory import get_llm  # ‚úÖ Path absoluto
from backend.agents.mapas.prompts.divisor_prompts import SYSTEM_PROMPT, USER_PROMPT_TEMPLATE  # ‚úÖ Path absoluto
from backend.utils.logger import logger  # ‚úÖ Path absoluto
from datetime import datetime
from pydantic import BaseModel, Field
from typing import List


# ============================================
# MODELS PARA STRUCTURED OUTPUT (AJUSTADO)
# ============================================

class ParteDivisao(BaseModel):
    """Representa uma parte da divis√£o - AGORA COM CONTE√öDO COMPLETO."""
    numero: int = Field(description="N√∫mero da parte (1, 2, 3...)")
    titulo: str = Field(description="T√≠tulo descritivo e espec√≠fico da parte")
    conteudo_completo: str = Field(description="Texto completo da parte (copiado da fundamenta√ß√£o)")
    estimativa_mapas: int = Field(ge=1, le=3, description="Quantos mapas mentais para esta parte (1-3)")


class DivisaoConteudo(BaseModel):
    """Resposta estruturada do LLM01."""
    num_partes: int = Field(ge=2, le=10, description="N√∫mero de partes (2-10)")
    justificativa: str = Field(description="Raz√£o da divis√£o escolhida")
    partes: List[ParteDivisao] = Field(description="Lista das partes com conte√∫do completo")


# ============================================
# NODE FUNCTION
# ============================================

async def dividir_conteudo_node(state: MindmapState) -> MindmapState:
    """
    LLM01: Analisa o conte√∫do e divide em partes.
    """
    
    logger.info("ü§ñ LLM01: Iniciando an√°lise para divis√£o de conte√∫do...")
    logger.info(f"üìä Usando provider: {state['llm01_provider']}")
    
    try:
        # ============================================
        # OBT√âM LLM CONFIGURADO
        # ============================================
        
        llm = get_llm(
            provider=state["llm01_provider"],
            temperature=0.3,
            max_tokens=12000
        )
        
        logger.debug(f"LLM configurado: {state['llm01_provider']}")
        
        # ============================================
        # PREPARA CONTE√öDO
        # ============================================
        
        fundamentacao = state["fundamentacao"]
        
        max_chars_input = 15000
        
        if len(fundamentacao) > max_chars_input:
            logger.warning(
                f"‚ö†Ô∏è Fundamenta√ß√£o muito longa ({len(fundamentacao)} chars). "
                f"Truncando para {max_chars_input} chars."
            )
            fundamentacao_para_analise = fundamentacao[:max_chars_input] + "\n\n[...conte√∫do truncado...]"
        else:
            fundamentacao_para_analise = fundamentacao
        
        logger.info(f"üìè Tamanho da fundamenta√ß√£o: {len(fundamentacao_para_analise)} chars")
        
        # ============================================
        # PREPARA PROMPT
        # ============================================
        
        user_prompt = USER_PROMPT_TEMPLATE.format(
            ramo_direito=state["ramo_direito"],
            topico=state["topico"],
            fundamentacao=fundamentacao_para_analise
        )
        
        logger.debug(f"Prompt preparado ({len(user_prompt)} chars)")
        
        # ============================================
        # CHAMA LLM COM STRUCTURED OUTPUT
        # ============================================
        
        logger.info("üìû Chamando LLM01...")
        
        structured_llm = llm.with_structured_output(DivisaoConteudo)
        
        response = await structured_llm.ainvoke([
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_prompt}
        ])
        
        logger.success(f"‚úÖ LLM01 respondeu: {response.num_partes} partes")
        
        # ============================================
        # VALIDA RESPOSTA
        # ============================================
        
        if not response.partes:
            raise ValueError("LLM01 n√£o retornou nenhuma parte na divis√£o")
        
        if len(response.partes) != response.num_partes:
            logger.warning(
                f"‚ö†Ô∏è Inconsist√™ncia: num_partes={response.num_partes} "
                f"mas len(partes)={len(response.partes)}"
            )
        
        for i, parte in enumerate(response.partes, 1):
            if not parte.conteudo_completo or len(parte.conteudo_completo) < 50:
                logger.error(
                    f"‚ùå Parte {i} tem conte√∫do insuficiente ({len(parte.conteudo_completo)} chars)"
                )
                raise ValueError(
                    f"Parte {i} n√£o tem conte√∫do adequado. "
                    "O LLM deve retornar o texto completo de cada parte."
                )
        
        # ============================================
        # PROCESSA DIVIS√ïES
        # ============================================
        
        divisoes_processadas = []
        
        for parte in response.partes:
            divisoes_processadas.append({
                "numero": parte.numero,
                "titulo": parte.titulo,
                "conteudo": parte.conteudo_completo,
                "estimativa_mapas": parte.estimativa_mapas
            })
            
            logger.info(
                f"  üìù Parte {parte.numero}: {parte.titulo}\n"
                f"     ‚îî‚îÄ Tamanho: {len(parte.conteudo_completo)} chars, "
                f"~{parte.estimativa_mapas} mapa(s)"
            )
            
            preview = parte.conteudo_completo[:100].replace('\n', ' ')
            logger.debug(f"     ‚îî‚îÄ Preview: {preview}...")
        
        # ============================================
        # VALIDA√á√ÉO FINAL
        # ============================================
        
        total_chars_partes = sum(len(p["conteudo"]) for p in divisoes_processadas)
        logger.info(f"üìä Total de caracteres nas partes: {total_chars_partes}")
        
        if total_chars_partes < len(fundamentacao) * 0.5:
            logger.warning(
                f"‚ö†Ô∏è As partes somam apenas {total_chars_partes} chars, "
                f"mas o original tem {len(fundamentacao)} chars. "
                "Pode haver perda de conte√∫do."
            )
        
        # ============================================
        # ATUALIZA ESTADO
        # ============================================
        
        state["divisoes"] = divisoes_processadas
        state["status"] = "gerando"
        state["partes_processadas"] = []
        
        state["logs"].append({
            "timestamp": datetime.now().isoformat(),
            "node": "dividir_conteudo",
            "level": "success",
            "message": f"Conte√∫do dividido em {response.num_partes} partes",
            "data": {
                "llm": state["llm01_provider"],
                "num_partes": response.num_partes,
                "justificativa": response.justificativa,
                "total_mapas_estimados": sum(p.estimativa_mapas for p in response.partes),
                "total_chars_partes": total_chars_partes,
                "tamanho_medio_parte": total_chars_partes // response.num_partes
            }
        })
        
        logger.success(
            f"‚úÖ Divis√£o conclu√≠da: {response.num_partes} partes, "
            f"~{sum(p.estimativa_mapas for p in response.partes)} mapas estimados\n"
            f"üìã Justificativa: {response.justificativa}"
        )
        
        return state
    
    except Exception as e:
        logger.error(f"‚ùå Erro no LLM01: {str(e)}")
        logger.exception(e)
        
        state["status"] = "erro"
        state["erro_msg"] = f"Erro na divis√£o de conte√∫do: {str(e)}"
        
        state["logs"].append({
            "timestamp": datetime.now().isoformat(),
            "node": "dividir_conteudo",
            "level": "error",
            "message": f"Erro no LLM01: {str(e)}",
            "data": {
                "llm": state["llm01_provider"],
                "error_type": type(e).__name__
            }
        })
        
        return state